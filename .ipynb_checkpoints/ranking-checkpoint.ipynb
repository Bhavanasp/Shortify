{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'rel_que' dataframe contains the questions that are relevant to the query which is the output of relevant questions model\n",
    "rel_que = pd.read_csv('data/relevant_questions.csv')\n",
    "#'ans' dataframe contains all the answers with their topics\n",
    "ans = pd.read_csv('data/keyword_answer.csv')\n",
    "#'kdf' dataframe contains the data of keywords for each topic\n",
    "kdf = pd.read_csv('data/keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the length of text\n",
    "def length_text(text):\n",
    "    if(type(text) != type(0.0)):\n",
    "        text = text.split(' ')\n",
    "        return len(text)\n",
    "    else:\n",
    "        return 0\n",
    "ans['ans length'] = ans['answer'].apply(length_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'rel_ans' dataframe contains the answers corresponding to the relevant questions to the query i.e, questions of 'rel_que' dataset\n",
    "rel_ans = pd.DataFrame()\n",
    "for i in enumerate(rel_que['id']):\n",
    "    rel_ans = pd.concat([ans[ans['id'] == i[1]], rel_ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['Topic 0', 'Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5', 'Topic 6', 'Topic 7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives one-hot encoding of the topics for the answers\n",
    "def get_dataframe(topic_list):\n",
    "    if(type(topic_list) == type(0.0)):\n",
    "        return pd.Series([0,0,0,0,0,0,0,0])\n",
    "    else:\n",
    "        topic_list = topic_list.split(', ')\n",
    "        tl = []\n",
    "        for topic in topics:\n",
    "            if(topic in topic_list):\n",
    "                val = 1\n",
    "            else: \n",
    "                val = 0\n",
    "            tl.append(val)\n",
    "        return pd.Series(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ans[topics] = rel_ans['topic list'].apply(get_dataframe)\n",
    "rel_ans.drop(columns=['topic list'], inplace = True)\n",
    "rel_ans['answer list'] = rel_ans['answer'] + rel_ans['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_text(text):\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     txt = \"\".join([txt.text for txt in soup.find_all(\"p\")])\n",
    "#     return txt\n",
    "\n",
    "# rel_ans['body'] = rel_ans['body'].apply(extract_text)\n",
    "rel_ans['title'] = rel_que['questions']\n",
    "rel_ans['question list'] = rel_ans['title'] + rel_ans['body']\n",
    "rel_ans.drop(columns=['body'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>questions</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48641350</td>\n",
       "      <td>How to merge two lists into a list of multiple...</td>\n",
       "      <td>0.799961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>46362972</td>\n",
       "      <td>Merge list of lists in python 3</td>\n",
       "      <td>0.785947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1158128</td>\n",
       "      <td>Merge sorted lists in python</td>\n",
       "      <td>0.750189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44476206</td>\n",
       "      <td>how to merge two list having dict</td>\n",
       "      <td>0.749920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>58971955</td>\n",
       "      <td>How to merge two dataframe?</td>\n",
       "      <td>0.709934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>14008075</td>\n",
       "      <td>How to merge many to many relations from one d...</td>\n",
       "      <td>0.372127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>55206146</td>\n",
       "      <td>Merge Pandas Dataframe with non-unique index w...</td>\n",
       "      <td>0.366641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>58678560</td>\n",
       "      <td>How to merge similar data into a custom field ...</td>\n",
       "      <td>0.365843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>50727548</td>\n",
       "      <td>How to merge multiple dataframes with the same...</td>\n",
       "      <td>0.354777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>58276538</td>\n",
       "      <td>How to merge/join empty dataframe with another...</td>\n",
       "      <td>0.354546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          questions     score\n",
       "0   48641350  How to merge two lists into a list of multiple...  0.799961\n",
       "1   46362972                    Merge list of lists in python 3  0.785947\n",
       "2    1158128                       Merge sorted lists in python  0.750189\n",
       "3   44476206                  how to merge two list having dict  0.749920\n",
       "4   58971955                        How to merge two dataframe?  0.709934\n",
       "..       ...                                                ...       ...\n",
       "95  14008075  How to merge many to many relations from one d...  0.372127\n",
       "96  55206146  Merge Pandas Dataframe with non-unique index w...  0.366641\n",
       "97  58678560  How to merge similar data into a custom field ...  0.365843\n",
       "98  50727548  How to merge multiple dataframes with the same...  0.354777\n",
       "99  58276538  How to merge/join empty dataframe with another...  0.354546\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>link</th>\n",
       "      <th>code</th>\n",
       "      <th>score</th>\n",
       "      <th>ans length</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>answer list</th>\n",
       "      <th>title</th>\n",
       "      <th>question list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4728</td>\n",
       "      <td>58276538.0</td>\n",
       "      <td>You can either use update:output:Or loc:output:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update\\nEmpty_DF.update(ROI_DF)\\r\\n\\n     a   ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You can either use update:output:Or loc:output...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4729</td>\n",
       "      <td>58276538.0</td>\n",
       "      <td>This is perfect case for DataFrame.update, whi...</td>\n",
       "      <td>https://pandas.pydata.org/pandas-docs/stable/r...</td>\n",
       "      <td>DataFrame.update\\nEmpty_DF.update(ROI_DF)\\r\\n\\...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is perfect case for DataFrame.update, whi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4730</td>\n",
       "      <td>58276538.0</td>\n",
       "      <td>In your case reindex_like</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reindex_like\\nyourdf=ROI_DF.reindex_like(Empty...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In your case reindex_likereindex_like\\nyourdf=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60589</td>\n",
       "      <td>50727548.0</td>\n",
       "      <td>You can put the different column into index an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pd.concat([plantsFrame.set_index(['plants']), ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You can put the different column into index an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27294</td>\n",
       "      <td>58678560.0</td>\n",
       "      <td>Your desired outputs are no longer really mode...</td>\n",
       "      <td>https://stackoverflow.com/a/35019122/12197595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39444</td>\n",
       "      <td>46362972.0</td>\n",
       "      <td>Use this code :Ouptut:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>list1= [['user1', 186, 'Feb 2017, Apr 2017', 5...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Use this code :Ouptut:list1= [['user1', 186, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18975</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>This might help</td>\n",
       "      <td>NaN</td>\n",
       "      <td>desiredlist = list(map(lambda y:[lst1,y],lst2)...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This might helpdesiredlist = list(map(lambda y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18976</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>You could achieve your desired output with ite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itertools.zip_longest\\nfillvalue\\n&gt;&gt;&gt; from ite...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You could achieve your desired output with ite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18977</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>Or you can use use append, but you need to cre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lst3 = []\\r\\nfor elem in lst2:\\r\\n    theNew =...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Or you can use use append, but you need to cre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18978</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from itertools import product\\r\\n\\r\\nlist(prod...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                             answer  \\\n",
       "4728   58276538.0    You can either use update:output:Or loc:output:   \n",
       "4729   58276538.0  This is perfect case for DataFrame.update, whi...   \n",
       "4730   58276538.0                          In your case reindex_like   \n",
       "60589  50727548.0  You can put the different column into index an...   \n",
       "27294  58678560.0  Your desired outputs are no longer really mode...   \n",
       "...           ...                                                ...   \n",
       "39444  46362972.0                             Use this code :Ouptut:   \n",
       "18975  48641350.0                                    This might help   \n",
       "18976  48641350.0  You could achieve your desired output with ite...   \n",
       "18977  48641350.0  Or you can use use append, but you need to cre...   \n",
       "18978  48641350.0                                                NaN   \n",
       "\n",
       "                                                    link  \\\n",
       "4728                                                 NaN   \n",
       "4729   https://pandas.pydata.org/pandas-docs/stable/r...   \n",
       "4730                                                 NaN   \n",
       "60589                                                NaN   \n",
       "27294      https://stackoverflow.com/a/35019122/12197595   \n",
       "...                                                  ...   \n",
       "39444                                                NaN   \n",
       "18975                                                NaN   \n",
       "18976                                                NaN   \n",
       "18977                                                NaN   \n",
       "18978                                                NaN   \n",
       "\n",
       "                                                    code  score  ans length  \\\n",
       "4728   update\\nEmpty_DF.update(ROI_DF)\\r\\n\\n     a   ...    2.0           6   \n",
       "4729   DataFrame.update\\nEmpty_DF.update(ROI_DF)\\r\\n\\...    3.0          44   \n",
       "4730   reindex_like\\nyourdf=ROI_DF.reindex_like(Empty...    1.0           4   \n",
       "60589  pd.concat([plantsFrame.set_index(['plants']), ...    0.0          12   \n",
       "27294                                                NaN    0.0          46   \n",
       "...                                                  ...    ...         ...   \n",
       "39444  list1= [['user1', 186, 'Feb 2017, Apr 2017', 5...    1.0           4   \n",
       "18975  desiredlist = list(map(lambda y:[lst1,y],lst2)...    0.0           3   \n",
       "18976  itertools.zip_longest\\nfillvalue\\n>>> from ite...    1.0          31   \n",
       "18977  lst3 = []\\r\\nfor elem in lst2:\\r\\n    theNew =...    1.0          16   \n",
       "18978  from itertools import product\\r\\n\\r\\nlist(prod...    1.0           0   \n",
       "\n",
       "       Topic 0  Topic 1  Topic 2  Topic 3  Topic 4  Topic 5  Topic 6  Topic 7  \\\n",
       "4728         0        1        0        0        0        0        0        0   \n",
       "4729         1        1        0        0        1        0        0        0   \n",
       "4730         0        1        0        0        0        0        0        0   \n",
       "60589        0        1        0        0        0        0        0        0   \n",
       "27294        0        1        0        0        0        0        0        1   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "39444        1        0        0        0        0        0        0        1   \n",
       "18975        0        0        0        0        0        0        0        0   \n",
       "18976        0        1        0        0        0        0        0        0   \n",
       "18977        1        1        0        0        0        0        0        0   \n",
       "18978        0        0        0        0        0        0        0        0   \n",
       "\n",
       "                                             answer list title question list  \n",
       "4728   You can either use update:output:Or loc:output...   NaN           NaN  \n",
       "4729   This is perfect case for DataFrame.update, whi...   NaN           NaN  \n",
       "4730   In your case reindex_likereindex_like\\nyourdf=...   NaN           NaN  \n",
       "60589  You can put the different column into index an...   NaN           NaN  \n",
       "27294                                                NaN   NaN           NaN  \n",
       "...                                                  ...   ...           ...  \n",
       "39444  Use this code :Ouptut:list1= [['user1', 186, '...   NaN           NaN  \n",
       "18975  This might helpdesiredlist = list(map(lambda y...   NaN           NaN  \n",
       "18976  You could achieve your desired output with ite...   NaN           NaN  \n",
       "18977  Or you can use use append, but you need to cre...   NaN           NaN  \n",
       "18978                                                NaN   NaN           NaN  \n",
       "\n",
       "[181 rows x 17 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a text processing function which converts text into lowercase, removes any characters like numbers, punctuation, \n",
    "# removes stopwords, stems the words and lemmatises them\n",
    "def text_process(text):\n",
    "    if(type(text) != type(0.0)):\n",
    "        text = text.lower()                              \n",
    "        text = re.sub(\"[^a-z]\", \" \", text)               \n",
    "        text = text.strip()                            \n",
    "        token = word_tokenize(text)\n",
    "        text = [i for i in token if not i in stop_words]\n",
    "        output = []\n",
    "        for word in text:\n",
    "            output.append(stemmer.stem(word))\n",
    "        text = []\n",
    "        for word in output:\n",
    "            text.append(lemmatizer.lemmatize(word))\n",
    "        text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answers and questions are of 'rel_ans' dataframe are preprocessed\n",
    "rel_ans['question list'] = rel_ans['question list'].apply(text_process)\n",
    "rel_ans['answer list'] = rel_ans['answer list'].apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers text scoring and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rel_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function for similarity of the answers with their corresponding questions\n",
    "def cosine_score(question, answer):\n",
    "    if(type(answer) == type(0.0) or type(question) == type(0.0)):\n",
    "        return 0\n",
    "    else:\n",
    "        sentences = [question, answer]\n",
    "        vectorizer = CountVectorizer()\n",
    "        vector = vectorizer.fit_transform(sentences)\n",
    "        text1 = vector.toarray()[0].tolist()\n",
    "        text2 = vector.toarray()[1].tolist()\n",
    "        cosc = 1-distance.cosine(text1, text2)\n",
    "        return cosc\n",
    "\n",
    "#a function that caluclates the sum of tfidf of each word in a text\n",
    "def entropy(text, tfidf_dict):\n",
    "    if(type(text) == type(0.0)):\n",
    "        return 0\n",
    "    else:\n",
    "        token = word_tokenize(text)\n",
    "        entropy = 0.0\n",
    "        for word in token:\n",
    "            try:\n",
    "                entropy = entropy + tfidf_dict[word]\n",
    "            except:\n",
    "                entropy = entropy + 0.0\n",
    "        return entropy\n",
    "\n",
    "#a function that calculates similarity with the query\n",
    "def query_sim_score(query, answer):\n",
    "    score = 0\n",
    "    if(type(answer) == type(0.0)):\n",
    "        return 0\n",
    "    else:\n",
    "        query = query\n",
    "        for q in query:\n",
    "            if(q in answer):\n",
    "                score =  score + 1\n",
    "        score = score/len(query)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text processes the query used in 'relevant questions' model\n",
    "query = 'merge two lists in python'\n",
    "query = text_process(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the frequency of words\n",
    "docs = data['answer list'].dropna().tolist()\n",
    "cv = CountVectorizer(stop_words = stop_words)\n",
    "word_count_vector = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<157x1345 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the tfidf score of each word\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit_transform(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces a dictionary of each word with its tfidf score where the word is the key and tfidf score of the word is the value\n",
    "tfidf_array = tfidf_transformer.idf_\n",
    "words = cv.get_feature_names()\n",
    "tfidf_dict = {}\n",
    "for i in range(0, len(tfidf_transformer.idf_)):\n",
    "    tfidf_dict[words[i]] = tfidf_array[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised_score():\n",
    "    sc = ((score - min_score)/(max_score - min_score))\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalises all the scores and returns their weighted sum\n",
    "def score(user_score, cosine_score, entropy_score, sim_score, min_user_score, max_user_score, min_cosine_score, max_cosine_score, min_entropy_score, max_entropy_score):\n",
    "    if(min_user_score == max_user_score):\n",
    "        user_score = user_score - min_user_score\n",
    "    else:\n",
    "        user_score = ((user_score - min_user_score)/(max_user_score - min_user_score))\n",
    "        \n",
    "    if(min_cosine_score == max_cosine_score):\n",
    "        cosine_score = cosine_score - min_cosine_score\n",
    "    else:\n",
    "        cosine_score = ((cosine_score - min_cosine_score)/(max_cosine_score - min_cosine_score))\n",
    "        \n",
    "    if(min_entropy_score == max_entropy_score):\n",
    "        entropy_score = entropy_score - min_entropy_score\n",
    "    else:\n",
    "        entropy_score = ((entropy_score - min_entropy_score)/(max_entropy_score - min_entropy_score))\n",
    "    return (user_score + cosine_score + entropy_score + 2 * sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-2af46ad52d83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtopic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcosc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mentro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msim_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_sim_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-c127bf979461>\u001b[0m in \u001b[0;36mcosine_score\u001b[1;34m(question, answer)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtext1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtext2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1199\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#produces a dataframe of the top 15 answers in each topic\n",
    "for topic in topics:\n",
    "    topic_data = data[data[topic]==1][['id', 'answer', 'link', 'code', 'score', 'answer list', 'question list']]\n",
    "    topic_data.dropna()\n",
    "    entropy_score = []\n",
    "    topic_df = pd.DataFrame()\n",
    "    for i in range(0, topic_data.shape[0]):\n",
    "        cosc = cosine_score(topic_data.iloc[i]['question list'], topic_data.iloc[i]['answer list'])\n",
    "        entro = entropy(topic_data.iloc[i]['answer list'], tfidf_dict)\n",
    "        sim_score = query_sim_score(query, topic_data.iloc[i]['answer list'])\n",
    "        topic_df = topic_df.append(pd.Series([topic_data.iloc[i]['id'], topic_data.iloc[i]['title'], topic_data.iloc[i]['answer'], topic_data.iloc[i]['link'], topic_data.iloc[i]['code'], topic_data.iloc[i]['score'], cosc, entro, sim_score]), ignore_index=True)\n",
    "    if topic_df.shape[0]==0:\n",
    "            continue\n",
    "    else:\n",
    "        topic_df.columns = ['id', 'title', 'answer', 'link', 'code', 'score', 'cosine score', 'entropy','sim score']\n",
    "        min_user_score = topic_df['score'].min()\n",
    "        max_user_score = topic_df['score'].max()\n",
    "        min_cosine_score = topic_df['cosine score'].min()\n",
    "        max_cosine_score = topic_df['cosine score'].max()\n",
    "        min_entropy_score = topic_df['entropy'].min()\n",
    "        max_entropy_score = topic_df['entropy'].max()\n",
    "        scores = []\n",
    "        for i in range(0, topic_df.shape[0]):\n",
    "            scores.append(score(topic_df.iloc[i]['score'], topic_df.iloc[i]['cosine score'], topic_df.iloc[i]['entropy'], \n",
    "                                topic_df.iloc[i]['sim score'], min_user_score, max_user_score, min_cosine_score, max_cosine_score,\n",
    "                                min_entropy_score, max_entropy_score))\n",
    "        topic_df.drop(columns = ['score', 'cosine score', 'entropy'], inplace=True)\n",
    "        topic_df['sc'] = scores\n",
    "        topic_df.sort_values(by = 'sc', ascending=False, inplace=True, kind='quicksort')\n",
    "        path = 'data/'+ topic +'.csv'\n",
    "        topic_df = topic_df.head(15)\n",
    "        topic_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
