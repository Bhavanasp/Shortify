{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "painted-tucson",
   "metadata": {},
   "source": [
    "## Summarization Model\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "celtic-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence - class that is used to store the sentences for each answer and their related info\n",
    "\n",
    "class sentence:\n",
    "    \n",
    "    def __init__(self, id, processedWords, originalWords):\n",
    "        self.id = id\n",
    "        self.processedWords = processedWords\n",
    "        self.originalWords = originalWords\n",
    "        self.wordFreq = self.sentWordFreq()\n",
    "\n",
    "    # Getter functions\n",
    "\n",
    "    def getId(self):\n",
    "        return self.id  # id to keep track of the question from which the answer is taken\n",
    "\n",
    "    def getProcessedWords(self):\n",
    "        return self.processedWords # preprocessed words of the sentence\n",
    "\n",
    "    def getOriginalWords(self):\n",
    "        return self.originalWords # original words of the sentence\n",
    "    \n",
    "    def getWordFreq(self):\n",
    "        return self.wordFreq  # dictionary of word frequencies\n",
    "\n",
    "    def sentWordFreq(self): # function to calculate the word frequencies\n",
    "        wordFreq = {}\n",
    "        for word in self.processedWords:\n",
    "            if word not in wordFreq.keys():\n",
    "                wordFreq[word] = 1\n",
    "            else:\n",
    "                wordFreq[word] = wordFreq[word] + 1\n",
    "        return wordFreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "internal-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# processAns - function to process an answer : tokenize, lowercase, punctuation removal and stemming and return sentence objects\n",
    "\n",
    "def processAns(id, answer):\n",
    "\n",
    "    sentence_token = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    lines = sentence_token.tokenize(answer.strip())\n",
    "\n",
    "    sentences = []\n",
    "    porter = nltk.PorterStemmer()\n",
    "\n",
    "    for line in lines:\n",
    "        originalWords = line[:]\n",
    "        line = line.strip().lower()\n",
    "\n",
    "        sent = nltk.word_tokenize(line)\n",
    "\n",
    "        stemmedSent = [re.sub(r'[^\\w\\s]', '', porter.stem(word)) for word in sent] # Stores the list of the processed words in each sentence\n",
    "\n",
    "        new_stemsent = []\n",
    "\n",
    "        for word in stemmedSent:\n",
    "            if word!='':\n",
    "                new_stemsent.append(word)\n",
    "\n",
    "        stemmedSent = new_stemsent\n",
    "        \n",
    "        if stemmedSent != [] :\n",
    "            sentences.append(sentence(id, stemmedSent, originalWords))\n",
    "\n",
    "    return sentences        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFs - function for TF score calculation\n",
    "\n",
    "def TFs(sentences):\n",
    "    \n",
    "    tfs = {}\n",
    "    \n",
    "    for sent in sentences:\n",
    "        wordFreqs = sent.getWordFreq()\n",
    "\n",
    "        # TF for each word\n",
    "\n",
    "        for word in wordFreqs.keys():\n",
    "            if tfs.get(word, 0)!=0:\n",
    "                tfs[word] = tfs[word] + wordFreqs[word]\n",
    "            else:\n",
    "                tfs[word] = wordFreqs[word]\n",
    "        \n",
    "    return tfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "roman-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDFs - function to calculate the IDF score\n",
    "\n",
    "def IDFs(sentences):\n",
    "    \n",
    "    N = len(sentences)\n",
    "    idf = 0\n",
    "    idfs = {}\n",
    "    words = {}\n",
    "    w2 = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "\n",
    "        for word in sent.getProcessedWords():\n",
    "\n",
    "            if sent.getWordFreq().get(word, 0) != 0:\n",
    "                words[word] = words.get(word, 0)+1\n",
    "\n",
    "    for word in words:\n",
    "        n = words[word]\n",
    "\n",
    "        try:\n",
    "            w2.append(n)                \n",
    "            idf = math.log10(float(N)/n)\n",
    "        except ZeroDivisionError:\n",
    "            idf = 0\n",
    "\n",
    "        idfs[word] = idf    # IDF for each word\n",
    "\n",
    "    return idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hundred-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TF_IDF - function to calculate the TF_IDF score for each word\n",
    "\n",
    "def TF_IDF(sentences):\n",
    "    tfs = TFs(sentences)\n",
    "    idfs = IDFs(sentences)\n",
    "    retval = {}\n",
    "\n",
    "    for word in tfs:\n",
    "        tf_idfs = tfs[word]*idfs[word] # The calulation step\n",
    "\n",
    "        if retval.get(tf_idfs, None) == None:\n",
    "            retval[tf_idfs] = [word]\n",
    "        else:\n",
    "            retval[tf_idfs].append(word)\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "macro-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentenceSim - function to calculate the similarity between two sentences with the help of the IDF scores\n",
    "\n",
    "def sentenceSim(sentence1, sentence2, IDF):\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    # sentence2\n",
    "\n",
    "    for word in sentence2.getProcessedWords():\n",
    "        numerator+= sentence1.getWordFreq().get(word,0) * sentence2.getWordFreq().get(word,0) *  IDF.get(word,0) ** 2\n",
    "\n",
    "    # sentence1\n",
    "\n",
    "    for word in sentence1.getProcessedWords():\n",
    "        denominator+= ( sentence1.getWordFreq().get(word,0) * IDF.get(word,0) ) ** 2\n",
    "\n",
    "    # calculation of similarity\n",
    "\n",
    "    try:\n",
    "        return numerator / math.sqrt(denominator)\n",
    "    except ZeroDivisionError:\n",
    "        return float(\"-inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "widespread-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildBase - function to make a sentence that has the highest TF_IDF scores\n",
    "\n",
    "def buildBase(sentences, TF_IDF_dict, n):\n",
    "\n",
    "    scores = TF_IDF_dict.keys()\n",
    "    sorted(scores, reverse=True) # Sorting in the decreasing order og TF IDF scores\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    baseWords = []\n",
    "    \n",
    "    # Adding the highest TF_IDF scored words\n",
    "\n",
    "    while(i<n):\n",
    "        words = TF_IDF_dict[list(scores)[j]]\n",
    "        for word in words:\n",
    "            baseWords.append(word)\n",
    "            i = i+1\n",
    "            if(i>n):\n",
    "                break\n",
    "        j = j+1\n",
    "\n",
    "        return sentence(\"base\", baseWords, baseWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prescription-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestSentence - function to get the sentence that has highest similarity with the base\n",
    "\n",
    "def bestSentence(senteces, base, IDF):\n",
    "    best_sentence = None\n",
    "    maxVal = float(\"-inf\")\n",
    "\n",
    "    for sent in sentences:\n",
    "        similarity = sentenceSim(sent, base, IDF)\n",
    "\n",
    "        if similarity > maxVal:\n",
    "            best_sentence = sent\n",
    "            maxVal = similarity\n",
    "\n",
    "    if best_sentence != None:\n",
    "        sentences.remove(best_sentence)\n",
    "\n",
    "    return best_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approved-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMRScore - function to calculate the MMR score\n",
    "\n",
    "def MMRScore(Si, base, Sj, lambta, IDF):\n",
    "    Sim1 = sentenceSim(Si, base, IDF)\n",
    "    l_expr = lambta * Sim1\n",
    "    value = [float(\"-inf\")]\n",
    "\n",
    "    for sent in Sj:\n",
    "        Sim2 = sentenceSim(Si, sent, IDF)\n",
    "        value.append(Sim2)\n",
    "\n",
    "    r_expr = (1-lambta)*max(value) # lambta is a hyper parameter\n",
    "    MMR_SCORE = l_expr-r_expr\n",
    "\n",
    "    return MMR_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "operational-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeSummary - function that makes summary based on the MMRscore\n",
    "\n",
    "def makeSummary(sentences, best_sentence, base, summary_len, lambta, IDF):\n",
    "    summary = [best_sentence] # Start with best sentence\n",
    "    sum_len = len(best_sentence.getProcessedWords())\n",
    "\n",
    "    while(sentences != [] and sum_len<summary_len):\n",
    "        MMRval={}\n",
    "        \n",
    "        # Assiging the MMR score for each sentence\n",
    "\n",
    "        for sent in sentences:\n",
    "            MMRval[sent] = MMRScore(sent, base, summary, lambta, IDF)\n",
    "        \n",
    "        maxxer = max(MMRval, key= lambda x: MMRval[x]) # Sorting the sentences in descending order of MMR score\n",
    "        if maxxer != None:\n",
    "            summary.append(maxxer) # Get the sentence with max MMR score and put it in the summary\n",
    "            sentences.remove(maxxer)\n",
    "            sum_len += len(maxxer.getProcessedWords())\n",
    "        \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fifteen-evolution",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------ORIGINAL-----------------------------------------------------------------------\n",
      "\n",
      "Both versions convey a topic; it’s pretty easy to predict that the paragraph will be about epidemiological evidence, but only the second version establishes an argumentative point and puts it in context. The paragraph doesn’t just describe the epidemiological evidence; it shows how epidemiology is telling the same story as etiology. Similarly, while Version A doesn’t relate to anything in particular, Version B immediately suggests that the prior paragraph addresses the biological pathway (i.e. etiology) of a disease and that the new paragraph will bolster the emerging hypothesis with a different kind of evidence. As a reader, it’s easy to keep track of how the paragraph about cells and chemicals and such relates to the paragraph about populations in different places. A last thing to note about key sentences is that academic readers expect them to be at the beginning of the paragraph. (The first sentence this paragraph is a good example of this in action!) This placement helps readers comprehend your argument. To see how, try this: find an academic piece (such as a textbook or scholarly article) that strikes you as well written and go through part of it reading just the first sentence of each paragraph. You should be able to easily follow the sequence of logic. When you’re writing for professors, it is especially effective to put your key sentences first because they usually convey your own original thinking. It’s a very good sign when your paragraphs are typically composed of a telling key sentence followed by evidence and explanation.\n",
      "\n",
      "-------------------------------------------------------------SUMMARY----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=https://www.youtube.com/watch?v=3vku3RvlAdc>Both versions convey a topic; it’s pretty easy to predict that the paragraph will be about epidemiological evidence, but only the second version establishes an argumentative point and puts it in context. </a><a href=https://www.youtube.com/watch?v=3vku3RvlAdc>The paragraph doesn’t just describe the epidemiological evidence; it shows how epidemiology is telling the same story as etiology. </a><a href=https://www.youtube.com/watch?v=3vku3RvlAdc>(The first sentence this paragraph is a good example of this in action!) </a><a href=https://www.youtube.com/watch?v=3vku3RvlAdc>You should be able to easily follow the sequence of logic. </a><a href=https://www.youtube.com/watch?v=3vku3RvlAdc>It’s a very good sign when your paragraphs are typically composed of a telling key sentence followed by evidence and explanation. </a><a href=https://www.youtube.com/watch?v=3vku3RvlAdc>A last thing to note about key sentences is that academic readers expect them to be at the beginning of the paragraph. </a"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarizer - function putting everythin togather\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "answer = \"Both versions convey a topic; it’s pretty easy to predict that the paragraph will be about epidemiological evidence, but only the second version establishes an argumentative point and puts it in context. The paragraph doesn’t just describe the epidemiological evidence; it shows how epidemiology is telling the same story as etiology. Similarly, while Version A doesn’t relate to anything in particular, Version B immediately suggests that the prior paragraph addresses the biological pathway (i.e. etiology) of a disease and that the new paragraph will bolster the emerging hypothesis with a different kind of evidence. As a reader, it’s easy to keep track of how the paragraph about cells and chemicals and such relates to the paragraph about populations in different places. A last thing to note about key sentences is that academic readers expect them to be at the beginning of the paragraph. (The first sentence this paragraph is a good example of this in action!) This placement helps readers comprehend your argument. To see how, try this: find an academic piece (such as a textbook or scholarly article) that strikes you as well written and go through part of it reading just the first sentence of each paragraph. You should be able to easily follow the sequence of logic. When you’re writing for professors, it is especially effective to put your key sentences first because they usually convey your own original thinking. It’s a very good sign when your paragraphs are typically composed of a telling key sentence followed by evidence and explanation.\"\n",
    "\n",
    "answers = [answer]\n",
    "\n",
    "links = [\"https://www.youtube.com/watch?v=as7xe8UQEr4\"]\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for answer in answers:\n",
    "    sentences = sentences + processAns(\"0\", answer)\n",
    "    \n",
    "IDF = IDFs(sentences)\n",
    "TF_IDF_dict = TF_IDF(sentences)\n",
    "\n",
    "base = buildBase(sentences, TF_IDF_dict, 10)\n",
    "\n",
    "bestsent = bestSentence(sentences, base, IDF)\n",
    "\n",
    "summary = makeSummary(sentences, bestsent, base, 100, 0.5, IDF)\n",
    "\n",
    "final_summary = \"\"\n",
    "for sent in summary:\n",
    "    final_summary = final_summary + \"<a href\"+ \"=\" + links[int(sent.id)] + \">\" + sent.getOriginalWords() + \" </a>\"\n",
    "final_summary = final_summary[:-1]\n",
    "\n",
    "print('-------------------------------------------------------------ORIGINAL-----------------------------------------------------------------------\\n')\n",
    "print(answer)\n",
    "print('\\n-------------------------------------------------------------SUMMARY----------------------------------------------------------------------\\n')\n",
    "display(HTML(final_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-fence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
