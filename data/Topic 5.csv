id,answer,link,code,sim score,sc
57015170.0,"First of all, I assumed you've not repeated your strings correctly (like ""hi, this is an example line."" != ""hi, this is edited line."") by mistake, not on purpose (that I can't figure out).I named the accumulative file common.doc to distinct from the other .txt files in the target directory. Also, this example code implies all the files are in the same directory.And after common.doc editing:And a solution for multiline text (merging stays with .strip() removed on content writing), not suitable for hundreds of thousands of files tho...",,"common.doc
.txt
# merging.py
import os
import glob

with open(""common.doc"", ""w"") as common:
    for txt in glob.glob(""./*.txt""):
        with open(txt, ""r"") as f:
            content = f.read()
        common.write(""{} ({})\n"".format(os.path.basename(txt), content))

common.doc
# splitting.py
with open(""common.doc"", ""r"") as common:
    for line in common:
        name = line[:line.find("" ("")]
        text = line[line.find("" ("")+2:line.rfind("")"")]
        with open(name, ""w"") as f:
            f.write(text)

.strip()
# splitting2.py
with open(""common.doc"", ""r"") as common:
    everything = common.read()
elements = everything.split("")"")
for elem in elements:
    name = elem[:elem.find("" ("")].strip()
    text = elem[elem.find("" ("")+2:]
    if name:
        with open(name, ""w"") as f:
            f.write(text)
",1.0,4.026044283858559
1158128.0,I like Roberto Liffredo's answer. I didn't know about heapq.merge(). Hmmmph.Here's what the complete solution looks like using Roberto's lead:Or:,,"class Obj(object):
    def __init__(self, p) :
        self.points = p
    def __cmp__(self, b) :
        return cmp(self.points, b.points)
    def __str__(self):
        return ""%d"" % self.points

a = [Obj(1), Obj(3), Obj(8)]
b = [Obj(1), Obj(2), Obj(3)]
c = [Obj(100), Obj(300), Obj(800)]

import heapq

sorted = [item for item in heapq.merge(a,b,c)]
for item in sorted:
    print item

for item in heapq.merge(a,b,c):
    print item
",0.95,3.5580328774728307
35526224.0,"so in your current definition there is the issue with:which returns an array, but you want this to be your new dict as I understand it, so replace this withallthough to be fair implementing greenwolf's suggestion looks better for the elegance of the programEDIT**
your final result should look something like this:in your example, your array has a key:value pair and then another dict without a key. this is not allowed. arrays can have any objects but only integers as keys. dicts can have any hashable object as key and any other type as value, for a key:value pair. so your options are either use array where index number directly relates to item id:where dict(id) looks like one of your dicts:it can even be a list of dicts:or you can use dicts as was suggested:",,"idJson=json.dumps(list(ServiceSubCategory.objects.values_list('id',flat=True)))

idJson={i:[] for i in list(ServiceSubCategory.objects.values_list('id',flat=True))}

def service(request):
    idList = list(ServiceSubCategory.objects.values_list('id',flat=True))
    idJson = {i:[] for i in idList}
    for i in idJson:
        cat = ServiceSubCategory.objects.get(id=i)
        dictionary=[obj.as_json() for obj in Service.objects.filter(service_sub_category=cat)]
        idJson[i].append(dictionary)
    return HttpResponse(idJson, content_type='application/json')

[dict1,dict2,dict3, etc..] 

{""caption_fa"": ""some value"", ""caption_en"": ""something"", ""id"": 2, ""img_fa"": ""img/default_service.png""}

[[dict1,dict3],[dict2,dict4]]

{'1': [dict1,dict2], '2': [dict3,dict4]}
",1.0,3.34473069118868
52426495.0,Found a solution (probably not an elegant one). ,,"df = pd.read_csv(file_name, parse_dates=[0], index_col=0, sep=',')
df['Date'] = df.index.date
df['Time'] = df.index.time
df['Time'] = df['Time'].astype(str)

df = df[df['Time'] != '22:00:00']

list_date = set(df['Date'])
list_time = set(df['Time'])

list_date = sorted(list_date)
list_time = sorted(list_time)

iterables = [list_date, list_time]
indexed = pd.MultiIndex.from_product(iterables, names=['date', 'time'])

df_index_date = indexed.get_level_values(0)
df_index_time = indexed.get_level_values(1)

df_joined = pd.DataFrame(df_index_date.astype(str) + ' ' + df_index_time.astype(str))
df_joined = df_joined.reset_index()
df_joined = df_joined.set_index(df_joined[0])
del df_joined['index']
del df_joined[0]

df_final = df_joined.join(df)
df_final = df_final.reset_index(drop=True)
df_final = df_final.set_index(indexed)
",0.9,3.322337711269286
41865577.0,what is the difference with @Geoff's answer and this one?,,"for x in range(0, len(df)):
    for y in range(0, len(df1)):
        if (df.iloc[x,'ip_address'] <= df1.iloc[y,'upper_bound_ip_address'] and (df.iloc[x,'ip_address'] >= df1.iloc[y,'lower_bound_ip_address']):
            df['country']=df1.iloc[y,'country']
",0.85,3.251158029738637
35526224.0,"So, instead of two JSONs, I converted the forst array to a string array ([""1"",""2"",""3"",...]) and using zip I've merged two arrays and then converted it to a JSON:And the result is:",,"[""1"",""2"",""3"",...]
zip
idArray='[""1"",""2"",""3"",...]'
dictionaries='[[{""caption_fa"": ""some value"", ""caption_en"": ""something"", ""id"": 2},
{""caption_fa"": ""somthing"", ""caption_en"": ""somthing"", ""id"": 1}],
[{""caption_fa"": ""some value"", ""caption_en"": ""something"", ""id"": 3},
{""caption_fa"": ""somthing"", ""caption_en"": ""somthing"", ""id"": 4}]]'
import json
theArray = dict(zip(idArray, dictionaries))
theJson =  json.dumps(theArray )

[[""1"":{""caption_fa"": ""some value"", ""caption_en"": ""something"", ""id"": 2},
    {""caption_fa"": ""somthing"", ""caption_en"": ""somthing"", ""id"": 1}],
    [""2"":{""caption_fa"": ""some value"", ""caption_en"": ""something"", ""id"": 3},
    {""caption_fa"": ""somthing"", ""caption_en"": ""somthing"", ""id"": 4}]]
",1.0,2.8647920231912534
44109813.0,"Why don't you try to use append, even though it is not the most elegant way ?For write files use open()
For example, ",,"    A =

    [('This', 'DT'),
     ('shoe', 'NN'),
     ('is', 'BEZ'),
     ('of', 'IN'),
     ('Blue', 'JJ-TL'),
     ('color', 'NN'),
     ('.', '.')]

    B =
    [('This', 'Other'),
     ('shoe', 'Product'),
     ('is', 'Other'),
     ('of', 'Other'),
     ('Blue', 'Color'),
     ('color', 'Other'),
     ('.', 'Other')]

    Title = 
    [('This', ),
     ('shoe', ),
     ('is', ),
     ('of', ),
     ('Blue', ),
     ('color', ),
     ('.', )]

    for j, item in enumerate(A):
        Title[j].append(item)
        Title[j].append(B[j][1])

    for tuple in Title:
        line = '{0[0]} {0[1]} {0[2]}'.format(tuple)

    f = open('This/is/your/destination/file.txt', 'w')
    # Here you do something

    f.write( )
    f.close()
",1.0,2.6733399218079024
43948049.0,"This can be achieved in much simple way in shell as:(Note: Don't use .csv in extension as it will cause inconsistency with find. After this command is finished, file can be renamed as .csv",,"find . -name ""*.csv"" | xargs cat > mergedCSV
",1.0,2.644682318314433
52502495.0,This is just elaborating on Arihant's answer :If you want to save it as a variable:,,"Enter3 = Enter1 + Enter2
for all in Enter3:
    print(all)

output = []
for all in Enter3:
   output.append(all)
string_output = "" "".join(output)
print(string_output)
",0.9,2.2748417367042513
43794802.0,"That's the editor that is opened so that you can write the commit message. That means the merge went well, no conflicts. Just set the comment, save the file and quit and the merge revision should be done.",,,0.0,0.0
