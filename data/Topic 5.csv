answer,link,code,sc
"Updated answer courtesy @OP:(Old Answer - don't use)You donâ€™t have to create a variation each circle. Chain them:Update: Reduce is awesome in simplicity and speed, but for readability, it is less readable compared to mergers: We could DRY the code:",,"dfs = [df1, df2, df3, df4, df5] 
from functools import partial 
outer_merge = partial(pd.merge, how='outer') 
reduce(outer_merge, dfs)

 df= df5.merge(df4[['code', 'name']],
            left_on='provinceCode', 
            right_on='code', 
            how='left'
            ).merge(df3[['code', 'name']], 
            left_on='areaCode', 
            right_on='code', 
            how = 'left'
            ).merge(df2[['code', 'name']], 
            left_on='areaCode',
            right_on='code',
            how ='left'
            ).merge(df1[['provinceCode', 'provinceName']],
            left_on='provinceCode',
            right_on='code',
            how='left')

common_joins = dict(right_on='code', how='left')
common_columns = ['code', 'name']

df= df5.merge(df4[common_columns],
            left_on='provinceCode', 
            **common_joins
            ).merge(df3[common_columns], 
            left_on='areaCode', 
            **common_joins
            ).merge(df2[common_columns], 
            left_on='areaCode',
            **common_joins
            ).merge(df1[['provinceCode', 'provinceName']],
            left_on='provinceCode',
            **common_joins)
",
"You cannot have multiple colors in a label. If you want multiple colors, use a one-line Text widget, or use a canvas with a text item. Here's a quick and dirty example using a text widget. It doesn't do smooth scrolling, doesn't use any real data, and leaks memory since I never trim the text in the input widget, but it gives the general idea:",,"import Tkinter as tk
import random

class Example(tk.Frame):
    def __init__(self, parent):
        tk.Frame.__init__(self, parent)
        self.ticker = tk.Text(height=1, wrap=""none"")
        self.ticker.pack(side=""top"", fill=""x"")

        self.ticker.tag_configure(""up"", foreground=""green"")
        self.ticker.tag_configure(""down"", foreground=""red"")
        self.ticker.tag_configure(""event"", foreground=""black"")

        self.data = [""AAPL"", ""GOOG"", ""MSFT""]
        self.after_idle(self.tick)

    def tick(self):
        symbol = self.data.pop(0)
        self.data.append(symbol) 

        n = random.randint(-1,1)
        tag = {-1: ""down"", 0: ""even"", 1: ""up""}[n]

        self.ticker.configure(state=""normal"")
        self.ticker.insert(""end"", "" %s %s"" % (symbol, n), tag)
        self.ticker.see(""end"")
        self.ticker.configure(state=""disabled"")
        self.after(1000, self.tick)

if __name__ == ""__main__"":
    root = tk.Tk()
    Example(root).pack(fill=""both"", expand=True)
    root.mainloop()
",
If you're looking to get two colours on the same line you can use several labels and use .grid() to get them on the same line.If you know you wanted two words and two colours for example you can use something like this:Or if you wanted to have a different colours for each word in a string for example:,,".grid()
root = Tk()
Label(root,text=""red text"",fg=""red"").grid(column=0,row=0)
Label(root,text=""green text"",fg=""green"").grid(column=0,row=1)
mainloop()

words = [""word1"",""word2"",""word3"",""word4""]
colours = [""blue"",""green"",""red"",""yellow""]

for index,word in enumerate(words):
    Label(window,text = word,fg=colours[index]).grid(column=index,row=0)
",
"To not loose the position when inserting prediction in the missing values you can use this approach, in example:To get the complete data merged in one pandas dataframe first get the known part together:If there is no missing value would do the job.",,"# merge train part of the data into a dataframe    
X_train = X_train.sort_index()
    y_train = y_train.sort_index()
    result = pd.concat([X_train,X_test])

# if need to convert numpy array to pandas series: 
# prediction = pd.Series(prediction)


# here is the magic
result['specie'][result['specie'].isnull()] = prediction.values
",
"According to the documentation you can pass in the axes you want to plot to. Therefore, your code would become:",https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html,"fig, ax = plt.subplots()

df1.plot(x = 'Interval', y = 'Trend', ax=ax)
df2.plot(x = 'Value', y = 'Reliability', ax=ax)

ax.set_yscale(""log"")
plt.show()
",
I thinkis the function you need.https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.minors.contracted_nodes.html,https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.minors.contracted_nodes.html,"nx.contracted_nodes
",
"If I understand correctly, you want to recursively merge the nodes until there is no overlap between the edges. My idea was to start with a fully connected graph and ""recursively"" merge the nodes. Here is a 'fake' recursive implementation. EDIT: I'm not too sure why networkx is necessary here, it could be done with just dicts (maybe more clear). ",https://i.stack.imgur.com/7rS6L.png,"import networkx as nx

# file you provided
with open('temp.txt', 'r') as f:
    lines = f.readlines()



nodes = {}
for idx, line in enumerate(lines):
    authors, title, venue = line.split('<>')[1:4]
    authors = set(authors.split(','))
    nodes[idx] = dict(authors = authors, title = (title, ))

G = nx.complete_graph(len(nodes))
nx.set_node_attributes(G, nodes)


def merge_recursive(G, target = 'authors'):
    """"""
    Keeps merging if there is overlap between nodes
    """"""
    # check edges
    while G.edges():
        for (i, j) in G.edges():
            overlap = G.nodes()[i][target].intersection(G.nodes()[j][target])
            # copy values
            if overlap:
                tmp = {}
                for k, v in G.nodes()[i].items():
                    if isinstance(v, set):
                        tmp[k] = v.union(G.nodes()[j][k])
                    else:
                        tmp[k] = v + G.nodes()[j][k]

                nx.set_node_attributes(G, {i: tmp})
                G.remove_node(j)
            # no overlap remove edge
            else:
                G.remove_edge(i, j)
            break
    return G

merged = merge_recursive(G.copy())

from matplotlib.pyplot import subplots

fig, (left, right) = subplots(1, 2, figsize = (10,  5))
nx.draw(G, ax = left, with_labels = 1)
nx.draw(merged, ax = right, with_labels = 1)

left.set_title('Before merging')
right.set_title('After merging')
fig.show()
",
what is the difference with @Geoff's answer and this one?,,"for x in range(0, len(df)):
    for y in range(0, len(df1)):
        if (df.iloc[x,'ip_address'] <= df1.iloc[y,'upper_bound_ip_address'] and (df.iloc[x,'ip_address'] >= df1.iloc[y,'lower_bound_ip_address']):
            df['country']=df1.iloc[y,'country']
",
"You should know the shape of returned array. Suppose, myArray.shape = (2, 4)
Then",,"allArrays = np.empty((0, 4))
for x in range(0, 1000):
    myArray = myFunction(x)
    allArrays = np.append(allArrays, myArray, axis = 0)
",
"A little bit tricky , using shift create the groupkey , then agg ",,"shift
agg
df.fillna('NaN',inplace=True) # notice here NaN always no equal to NaN, so I replace it with string 'NaN'
df.groupby((df.drop('Y',1)!=df.drop('Y',1).shift()).any(1).cumsum()).\
     agg(lambda x : ','.join(x) if x.name=='Y' else x.iloc[0])
Out[19]: 
         Y   X1    X2    X3    X4    X5
1    A,B,C  NaN -3810  TRUE  None  None
2  D,E,F,G  NaN -3810  None  None  None
3        H  NaN -3810  TRUE  None  None
",
"I would suggest using the TIFF file format. Most TIFF files are striped (one or more scan lines are stored as a block on file), but it is possible to write tiled TIFF files (where the image is divided into tiles, and each is stored as an independent block on file).LibTIFF is the canonical way of reading and writing TIFF files. It has an easy way of creating a new TIFF file, and add tiles one at the time. Thus, your program can create the TIFF file, obtain one sector, write it as (one or more) tiles to the TIFF file, obtain the next sector, etc. You would have to choose your tile size to evenly divide one sector.There is a Python binding to LibTIFF called, what else, PyLibTIFF. It should allow you to follow the above model from within Python. That same repository has pure Python module to read and write TIFF files, I don't know if that is able to write TIFF files in tiles, or if it allows to write them in chunks. There are many other Python modules for reading and writing TIFF files, but most will write one matrix as a TIFF file, rather than allow you to write a file one tile at a time.",http://www.simplesystems.org/libtiff/ https://github.com/pearu/pylibtiff,,
"pyvips can do exactly what you want very quickly and efficiently. For example:The access=""sequential"" option tells pyvips that you want to stream the image. It will only load pixels on demand as it generates output, so you can merge enormous images using only a little memory. The arrayjoin operator joins an array of images into a grid across tiles across. It has quite a few layout options: you can specify borders, overlaps, background, centring behaviour and so on.I can run it like this:So it joined 100 JPG images to make a 14,000 x 20,000 pixel mosaic in about 2.5s on this laptop, and from watching top, needed about 300mb of memory. I've used it to join over 30,000 images into a single file, and it would go higher. I've made images of over 300,000 by 300,000 pixels.The pyvips equivalent of PIL's paste is insert. You could use that too, though it won't work so well for very large numbers of images. There's also a command-line interface, so you could just enter:To join up a large set of JPG images.",https://pypi.org/project/pyvips/ https://libvips.github.io/libvips/API/current/libvips-conversion.html#vips-arrayjoin https://libvips.github.io/libvips/API/current/libvips-conversion.html#vips-insert,"import sys
import pyvips

images = [pyvips.Image.new_from_file(filename, access=""sequential"")
          for filename in sys.argv[2:]]
final = pyvips.Image.arrayjoin(images, across=10)
final.write_to_file(sys.argv[1])

access=""sequential""
arrayjoin
across
$ for i in {1..100}; do cp ~/pics/k2.jpg $i.jpg; done
$ time ../arrayjoin.py x.tif *.jpg 

real    0m2.498s
user    0m3.579s
sys 0m1.054s
$ vipsheader x.tif
x.tif: 14500x20480 uchar, 3 bands, srgb, tiffload

top
paste
insert
vips arrayjoin ""${echo *.jpg}"" x.tif --across 10
",
"This isn't pretty, but what if you did something like this:And this would be the general case:",,"df2 = DataFrame(df, copy=True)
df2[['lat2', 'lon2']] = df[['lat', 'lon']].shift(-1)
df2.set_index(['lat', 'lon', 'lat2', 'lon2'], inplace=True)
print(df2.loc[(12, 10, 13, 9)].reset_index(drop=True))

   car_id
0     100
1     120

raw_data = {'car_id': [100, 100, 100, 110, 110, 110, 110, 120, 120, 120, 120, 130],
            'lat': [10, 12, 13, 23, 13, 12, 12, 11, 12, 13, 14, 12],
            'lon': [15, 10, 9, 8, 9, 10, 2, 11, 10, 9, 8, 10],
           }
df = pd.DataFrame(raw_data, columns = ['car_id', 'lat', 'lon'])

raw_data = {
             'lat': [10, 12, 13],
             'lon': [15, 10, 9],
           }

coords = pd.DataFrame(raw_data, columns = ['lat', 'lon'])

def submatch(df, match):
    df2 = DataFrame(df['car_id'])
    for x in range(match.shape[0]):
        df2[['lat{}'.format(x), 'lon{}'.format(x)]] = df[['lat', 'lon']].shift(-x)

    n = match.shape[0]
    cols = [item for sublist in
        [['lat{}'.format(x), 'lon{}'.format(x)] for x in range(n)]
        for item in sublist]

    df2.set_index(cols, inplace=True)
    return df2.loc[tuple(match.stack().values)].reset_index(drop=True)

print(submatch(df, coords))

   car_id
0     100
",
Found a solution (probably not an elegant one). ,,"df = pd.read_csv(file_name, parse_dates=[0], index_col=0, sep=',')
df['Date'] = df.index.date
df['Time'] = df.index.time
df['Time'] = df['Time'].astype(str)

df = df[df['Time'] != '22:00:00']

list_date = set(df['Date'])
list_time = set(df['Time'])

list_date = sorted(list_date)
list_time = sorted(list_time)

iterables = [list_date, list_time]
indexed = pd.MultiIndex.from_product(iterables, names=['date', 'time'])

df_index_date = indexed.get_level_values(0)
df_index_time = indexed.get_level_values(1)

df_joined = pd.DataFrame(df_index_date.astype(str) + ' ' + df_index_time.astype(str))
df_joined = df_joined.reset_index()
df_joined = df_joined.set_index(df_joined[0])
del df_joined['index']
del df_joined[0]

df_final = df_joined.join(df)
df_final = df_final.reset_index(drop=True)
df_final = df_final.set_index(indexed)
",
"Create a conditional to find if there is an overlap between the two frames, create new columns based on the conditionals, and merge, using how='outer'What I observed from the data is that if the overlap (end-start) in df_1 is greater than or equal to the overlap in df_2, then add start_data_2, otherwise, leave as is. The calculation hinges on that; if it is a false premise OP, do let me know.",,"#create overlap columns

df_1['overlap']= df_1.end - df_1.start
df_2['overlap']= df_2.end - df_2.start

cond1 = df_1.overlap.ge(df_2.overlap)
df_1['key'] = np.where(cond1, df_2.some_data_2,'n1')
df_2['key'] = np.where(cond1, df_2.some_data_2,'n')

(pd
 .merge(df_1,df_2,
        how='outer',
        on='key',
        suffixes = ('_1','_2'))
 .drop(['key','overlap_1','overlap_2'],
       axis=1)
  )

   start_1  end_1   some_data_1 start_2 end_2   some_data_2
0   0.0     5.0        AA        0.0    5.0      AA_AA
1   10.0    17.0       BB       12.0    17.0     BB_BB
2   23.0    28.0       CC       23.0    25.0     CC_CC
3   35.0    41.0       DD       NaN     NaN      NaN
4   NaN     NaN        NaN      55.0    62.0     DD_DD
",
