id,answer,link,code,sim score,sc
46362972.0,"I managed to do what you intended by changing your format. I convert all your sublists into dict with the key user.Because it easier to merge dict and the order of user in your sublists doesn't matter.The last steps is to iterate over the merged dict of list1 and list2 and do your special operation. As I understood, is to take the before last number of list1 and merge it with list2. Then you recreate your desired sublist.Output:EDITIt seems I make a mistake and your list1 have to check all the content of list2, in that case you should make a dict of list2 first and apply your specific condition after. eg:output:Note: we can get rid of defaultdict since the same key is not being to be added twice.",,"dict
user
user
dict
list1
list2
list1
list2
from itertools import chain
from collections import defaultdict

list1 = [['user1', 186, 'Feb 2017, Apr 2017', 550, 555], ['user2', 282, 'Mai 2017', 0, 3579], ['user3', 281, 'Mai 2017', 10, 60]]
list2 = [['user1', 186, 'Feb 2017, Mar 2017, Mai 2017', 0, 740],['user2', 282, 'Feb 2017', 0, 1000], ['user4', 288, 'Feb 2017', 60, 10]]

# Transform list to dict with key as 'userN'
def to_dict(lst): return {x[0]: x[1:] for x in lst} 

# Now create a dict that combined list of user1..N+1
tmp_dict = defaultdict(list)
for k, v in chain(to_dict(list1).items(), to_dict(list2).items()):
  tmp_dict[k].append(v)

desired_output = []
for k, v in tmp_dict.items():
  if len(v) == 2:
    v[1][-2] = v[0][-2] # Take the before last of list1 to remplace with before last one of list2
    desired_output.append([k] + v[1])
  else:
    desired_output.append([k] + v[0])

print(desired_output)

[['user1', 186, 'Feb 2017, Mar 2017, Mai 2017', 550, 740], ['user2', 282, 'Feb 2017', 0, 1000], ['user3', 281, 'Mai 2017', 10, 60], ['user4', 288, 'Feb 2017', 60, 10]]

list1
list2
dict
list2
from itertools import chain

list1 = [['user1', 186, 'Feb 2017, Apr 2017', 550, 555], ['user2', 282, 'Mai 2017', 0, 3579], ['user3', 281, 'Mai 2017', 10, 60]]
list2 = [['user1', 186, 'Feb 2017, Mar 2017, Mai 2017', 0, 740],['user2', 282, 'Feb 2017', 0, 1000], ['user4', 288, 'Feb 2017', 60, 10]]

# Transform list to dict with key as 'userN'
def to_dict(lst): return {x[0]: x[1:] for x in lst} 

# First, transfrom list2 to dict
list2_dict = {}
for k, v in to_dict(list2).items():
  list2_dict[k] = v

# Then iterate on list1 to compare
desired_output = []
for k, v in to_dict(list1).items():
  if k in list2_dict: # key of list1 exists in list2
    list2_dict[k][-2] = v[-2] # replace value
    desired_output.append([k] + list2_dict[k]) # Then add list2
    list2_dict.pop(k) # And remove it from old dict
  else: # list1 does not exists in list2
    v[-1] = 0 # Set last element to zero
    desired_output.append([k] + v)

for k, v in list2_dict.items(): # Now add elements present only in list2
  desired_output.append([k] + v)

print(desired_output)

[['user1', 186, 'Feb 2017, Mar 2017, Mai 2017', 550, 740], ['user2', 282, 'Feb 2017', 0, 1000], ['user3', 281, 'Mai 2017', 10, 0], ['user4', 288, 'Feb 2017', 60, 10]]

defaultdict",1.0,3.911960755974062
14008075.0,"First off, don't feel bad as I had to test this to see why it doesn't work, and I wrote the thing.The merge() use case is one where you're taking some kind of in-application data, either from an offline cache or some locally modified structure, and moving it into a new Session.   merge() is mostly about merging changes, so when it sees attributes that have no ""change"", it assumes no special work is needed.   So it skips unloaded relationships.  If it did follow unloaded relationships, the merge process would become a very slow and burdensome operation as it traverses the full graph of relationships loading everything recursively, potentially loading a significant portion of the database into memory for a highly interlinked schema.  The ""copy from one database to another"" use case here was not anticipated.the data does go in if you just make sure all those edges are loaded ahead of time, here's a demo.   the default cascade is ""save-update, merge"" also so you don't have to specify that.",,"from sqlalchemy import create_engine, Column, String, Integer, ForeignKey
from sqlalchemy.orm import Session, relationship, backref, immediateload
from sqlalchemy.ext.declarative import declarative_base
import os

Base = declarative_base()

class Person(Base):
    __tablename__ = ""people""
    id = Column(Integer, primary_key=True)
    name = Column(String)

    def __init__(self, name):
        self.name = name


class Edge(Base):
    __tablename__ = ""edges""
    id = Column(Integer, primary_key=True)
    kid_id = Column(Integer, ForeignKey(""people.id""))
    parent_id = Column(Integer, ForeignKey(""people.id""))
    kid = relationship(""Person"", primaryjoin=""Edge.kid_id==Person.id"",
                       backref=backref(""parent_edges"",
                                       collection_class=set))
    parent = relationship(""Person"", primaryjoin=""Edge.parent_id==Person.id"",
                          backref=backref(""kid_edges"",
                                          collection_class=set))

    def __init__(self, kid, parent):
        self.kid = kid
        self.parent = parent

def teardown():
    for path in (""in.db"", ""out.db""):
        if os.path.exists(path):
            os.remove(path)

def fixture():
    engine = create_engine(""sqlite:///in.db"", echo=True)
    Base.metadata.create_all(engine)

    s = Session(engine)
    p1, p2, p3, p4, p5 = [Person('p%d' % i) for i in xrange(1, 6)]
    Edge(p1, p2)
    Edge(p1, p3)
    Edge(p4, p3)
    Edge(p5, p2)
    s.add_all([
        p1, p2, p3, p4, p5
    ])
    s.commit()
    return s

def copy(source_session):
    engine = create_engine(""sqlite:///out.db"", echo=True)
    Base.metadata.create_all(engine)

    s = Session(engine)
    for person in source_session.query(Person).\
            options(immediateload(Person.parent_edges),
                        immediateload(Person.kid_edges)):
        s.merge(person)

    s.commit()

    assert s.query(Person).count() == 5
    assert s.query(Edge).count() == 4

teardown()
source_session = fixture()
copy(source_session)
",1.0,3.8980041530991913
48123619.0,"I am assuming you want to create comment and reply(re-comment) on particular comment on detail page of Post model.You can create a View inspite of creating a CreateView for  CommentCreateView and ReCommentCreateView class and override post methodNow send ReCommentCreateForm and CommentCreateForm in context data of your DetailView class.In your comment.html you can use both variable to render form.Update your urls for all views like below.Access your post detail page using:
  http://localhost:8000/polls/post/1/",,"Post
View
CreateView
post
class CommentCreateView(generic.View):

   def post(self, request, *args, **kwargs):
      form = CommentCreateForm(request.POST)
      post = Post.objects.get(pk=kwargs['post_pk'])
      if form.is_valid():
        obj = form.save(commit=False)
        obj.target = post
        obj.save()
      return redirect('detail', pk=post.pk)

class ReCommentCreateView(generic.View):

   def post(self, request, *args, **kwargs):
      form = ReCommentCreateForm(request.POST)
      comment = Comment.objects.get(pk=kwargs['comment_pk'])
      if form.is_valid():
        obj = form.save(commit=False)
        obj.target = comment
        obj.save()
      return redirect('detail', pk=comment.target.pk)

ReCommentCreateForm
CommentCreateForm
class DetailView(generic.DetailView):
    model = Post
    template_name = 'comment.html'

    def get_context_data(self, **kwargs):
       context = super().get_context_data(**kwargs)
       context['comment_form'] = CommentCreateForm()
       context['recomment_form'] = ReCommentCreateForm()
       return context 

# comment form action url should have id of post.
<form action=""{% url 'comment' post_pk=post.id %}"" method=""post"">
   {{comment_form}}
   {% csrf_token %}
   <input class=""btn btn-primary"" type=""submit"" value=""comment""> 
</form>

# re-comment form action url should have id of comment on which user is replying.
<form action=""{% url 'recomment' comment_pk=comment.id %}"" method=""post"">
   {{recomment_form}}
   {% csrf_token %}
   <input class=""btn btn-primary"" type=""submit"" value=""re-comment"">
</form>

urlpatterns = [    
    # Detail page of post url 
    path('post/<int:pk>/', views.DetailView.as_view(), name='post'),
    # CommentCreateView page url to create comment on post
    path('comment/<int:post_pk>/', views.CommentCreateView.as_view(), name='comment'),
    # ReCommentCreateView page url to create re-comment on comment
    path('recomment/<int:comment_pk>/', views.ReCommentCreateView.as_view(), name='recomment'),
]

http://localhost:8000/polls/post/1/",1.0,3.8857960893660053
45212537.0,"Using pandas:To get rid of duplicate rows as well:This will not get rid of duplicates as the dataframe is created, but after. So a dataframe gets created by concatenating all of the files. Then it is de-duplicated. The final dataframe can then be saved to csv.",,"import pandas as pd

interesting_files = glob.glob(""/home/tcs/PYTHONMAP/test1/*.csv"") 
df = pd.concat((pd.read_csv(f, header = 0) for f in interesting_files))
df.to_csv(""output.csv"")

import pandas as pd

interesting_files = glob.glob(""/home/tcs/PYTHONMAP/test1/*.csv"") 
df = pd.concat((pd.read_csv(f, header = 0) for f in interesting_files))
df_deduplicated = df.drop_duplicates()
df_deduplicated.to_csv(""output.csv"")
",1.0,3.7329143512430614
43552785.0,Consider a concatenation with merge which would translate your SQL query as OR is often analogous to a UNION:,,"OR
UNION
pd.concat([pd.merge(table_A, table_B, on='one'),
           pd.merge(table_A, table_B, left_on='two', right_on='one')])
",0.95,3.363089736564874
50480244.0,"You need create MultiIndex in columns first, then reshape by unstack and last reset_index:If input is file better is use parameter header for MultiIndex:",http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html,"MultiIndex
unstack
reset_index
print (df)
      Sales    Sales1      Sales2
0  Jan 2000  Feb 2000  Month 2000
1      2000      3000        4000
2      7000      8000        3000

#MultiIndex by first row
df.columns = [df.columns, df.iloc[0]]
#remove first row by indexing - [1:]
df = df.iloc[1:].unstack().reset_index(name='val')
df.columns = ['a','b','c','val']
print (df)
        a           b  c   val
0   Sales    Jan 2000  0  2000
1   Sales    Jan 2000  1  7000
2  Sales1    Feb 2000  0  3000
3  Sales1    Feb 2000  1  8000
4  Sales2  Month 2000  0  4000
5  Sales2  Month 2000  1  3000

file
header
MultiIndex
import pandas as pd

temp=u""""""Sales;Sales1;Sales2
Jan 2000;Feb 2000;Month 2000
2000;3000;4000
7000;8000;3000""""""
#after testing replace 'pd.compat.StringIO(temp)' to 'filename.csv'
df = pd.read_csv(pd.compat.StringIO(temp), sep=';',header=[0,1])
print (df)

     Sales   Sales1     Sales2
  Jan 2000 Feb 2000 Month 2000
0     2000     3000       4000
1     7000     8000       3000

print (df.columns)
MultiIndex(levels=[['Sales', 'Sales1', 'Sales2'], ['Feb 2000', 'Jan 2000', 'Month 2000']],
           labels=[[0, 1, 2], [1, 0, 2]])

df = df.unstack().reset_index(name='val')
df.columns = ['a','b','c','val']
print (df)
        a           b  c   val
0   Sales    Jan 2000  0  2000
1   Sales    Jan 2000  1  7000
2  Sales1    Feb 2000  0  3000
3  Sales1    Feb 2000  1  8000
4  Sales2  Month 2000  0  4000
5  Sales2  Month 2000  1  3000
",0.95,3.218749036048162
57015170.0,"First of all, I assumed you've not repeated your strings correctly (like ""hi, this is an example line."" != ""hi, this is edited line."") by mistake, not on purpose (that I can't figure out).I named the accumulative file common.doc to distinct from the other .txt files in the target directory. Also, this example code implies all the files are in the same directory.And after common.doc editing:And a solution for multiline text (merging stays with .strip() removed on content writing), not suitable for hundreds of thousands of files tho...",,"common.doc
.txt
# merging.py
import os
import glob

with open(""common.doc"", ""w"") as common:
    for txt in glob.glob(""./*.txt""):
        with open(txt, ""r"") as f:
            content = f.read()
        common.write(""{} ({})\n"".format(os.path.basename(txt), content))

common.doc
# splitting.py
with open(""common.doc"", ""r"") as common:
    for line in common:
        name = line[:line.find("" ("")]
        text = line[line.find("" ("")+2:line.rfind("")"")]
        with open(name, ""w"") as f:
            f.write(text)

.strip()
# splitting2.py
with open(""common.doc"", ""r"") as common:
    everything = common.read()
elements = everything.split("")"")
for elem in elements:
    name = elem[:elem.find("" ("")].strip()
    text = elem[elem.find("" ("")+2:]
    if name:
        with open(name, ""w"") as f:
            f.write(text)
",1.0,3.1988207325586675
41865577.0,"pandas
pd.merge_asof + querynumpy
np.searchsorted ",,"pandas
pd.merge_asof
query
pd.merge_asof(
    df.sort_values('ip_address'), df1,
    left_on='ip_address', right_on='lower_bound_ip_address'
).query('ip_address <= upper_bound_ip_address')[['ip_address', 'country']]

numpy
np.searchsorted
b = df1.values[:, :2].ravel()
c = df1.country.values
ip = df.ip_address.values
srch = b.searchsorted(ip) // 2
mask = (ip >= b[0]) & (ip <= b[-1])
df.loc[mask, 'country'] = c[srch[mask]]
",1.0,3.171004707931771
47667379.0,"You'll have to learn how templating works. Read this page on the docs to learn more: http://www.tornadoweb.org/en/stable/guide/templates.html#template-syntax After that, you can find the complete template syntax reference on this page: http://www.tornadoweb.org/en/stable/template.html#syntax-referenceAnyway, you can ""merge"" two templates and render them as one by using the {% include %} template tag. Example:Your Home1.html template should look roughly like this:Then render only the Home1.html from your request handler.This answer is far from perfect. You'll have to invest some time to actually learn about templates.",http://www.tornadoweb.org/en/stable/guide/templates.html#template-syntax http://www.tornadoweb.org/en/stable/template.html#syntax-reference,"{% include %}
Home1.html
<html>
    <!-- do something -->
    {% include 'Home2.html' %}
    <!-- do something else -->
</html>

Home1.html",1.0,3.0211817572297783
29370770.0,"With python's csv reader and writer,
reading from the files a.csv and b.csv, writing to c.csv:Creates file c.csv:(I assume that those braces and extra linebreaks in your csv code are just here on stackoverflow and not really part of your csv files? I also assume that a.csv and b.csv have the same length in lines.)",,"a.csv
b.csv
c.csv
# -*- coding: utf-8 -*-

import csv

with open('a.csv', 'r') as file_a:
    with open('b.csv', 'r') as file_b:
        with open('c.csv', 'w') as file_c:
            reader_a = csv.reader(file_a, delimiter=',')
            reader_b = csv.reader(file_b, delimiter=',')
            writer_c = csv.writer(file_c)

            for cols_a in reader_a:
                cols_b = reader_b.next()
                writer_c.writerow(cols_a + cols_b)

c.csv
a, b, c, d,o, p, q, r
e, f, g, h,s, t, u, v
i, j, k, l,w, x, y, z
",1.0,2.974098967293303
22306340.0,"Is there a reason you're avoiding creating some objects to manage this? If it were me, I'd go objects and do something like the following (this is completely untested, there may be typos):Now I can right code that looks like:This is just a starting point. Now you can you add methods that group (and sum) the expenditures list by decoration (e.g. ""I spent HOW MUCH on Twinkies last month???""). You can add a method that parses entries from a file, or emits them to a csv list. You can do some charting based on time.",,"#!/usr/bin/env python3

from datetime import datetime # why python guys, do you make me write code like this??
from operator import itemgetter

class BudgetCategory(object):
    def __init__(self, name, allowance):
        super().__init__()
            self.name = name # string naming this category, e.g. 'Food'
            self.allowance = allowance # e.g. 400.00 this month for Food
            self.expenditures = [] # initially empty list of expenditures you've made

    def spend(self, amount, when=None, description=None):
        ''' Use this to add expenditures to your budget category'''
        timeOfExpenditure = datetime.utcnow() if when is None else when #optional argument for time of expenditure
        record = (amount, timeOfExpenditure, '' if description is None else description) # a named tuple would be better here...
        self.expenditures.append(record) # add to list of expenditures
        self.expenditures.sort(key=itemgetter(1)) # keep them sorted by date for the fun of it

    # Very tempting to the turn both of the following into @property decorated functions, but let's swallow only so much today, huh?
    def totalSpent(self):
        return sum(t[0] for t in self.expenditures)

    def balance(self):
        return self.allowance - self.totalSpent()

budget = BudgetCategory(name='Food', allowance=200)
budget.spend(5)
budget.spend(8)

print('total spent:', budget.totalSpent())
print('left to go:', budget.balance())
",1.0,2.9460564551071036
52879192.0,"I suggest you to use json, which is specific for JSON object manipulation. You can do something like this:where json.load() convert a string to a json object, while json.dumps() convert a json to a string. The parameter indent let you print the object in the expanded way.",,"json
    import json

with open('example1.json') as f:
    data1 = json.load(f)

with open('example2.json') as f:
    data2 = json.load(f)

with open('example3.json') as f:
    data3 = json.load(f)

items1 = data1[""items""]
#print(json.dumps(items1, indent=2))
items2 = data2[""items""]
items3 = data3[""items""]

listitem = [items1, items2, items3]
finaljson = {""items"" : []}

finaljson[""items""].append(items1)
finaljson[""items""].append(items2)
finaljson[""items""].append(items3)
print(json.dumps(finaljson, indent=2))

with open('merged_json.json', ""w"") as f:
    f.write(json.dumps(finaljson, indent=2))

json.load()
json.dumps()
indent",1.0,2.927135841895867
60013509.0,"Your doing a ton of work to put a <table> tag into a table. Let pandas do that for you (it uses BeautifulSoup under the hood). Then to merge, there's 2 ways you can do it:1) Make one of the dataframes only have what is not contained in the other (However, keep columns that you will do the merge on).2) Drop columns from the second dataframe that are in the dataframe (again, make sure to not drop the columns you will do the merge on.OR",,"<table>
import pandas as pd

def scrape_data(url):
    stats = pd.read_html(url)[0]
    return stats


df1 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_advanced.html"")
df1 = df1[df1['Rk'] != 'Rk']

df2 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_per_poss.html"")
df2 = df2[df2['Rk'] != 'Rk']

uniqueCols = [ col for col in df2.columns if col not in df1.columns ]

# Below will do the same as above line
#uniqueCols = list(df2.columns.difference(df1.columns))

df2 = df2[uniqueCols + ['Player', 'Tm']]

df = df1.merge(df2, how='left', on=['Player', 'Tm'])

import pandas as pd

def scrape_data(url):
    stats = pd.read_html(url)[0]
    return stats


df1 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_advanced.html"")
df1 = df1[df1['Rk'] != 'Rk']

df2 = scrape_data(""https://basketball-reference.com/leagues/NBA_2020_per_poss.html"")
df2 = df2[df2['Rk'] != 'Rk']

dropCols = [ col for col in df1.columns if col in df2.columns and col not in ['Player','Tm']]
df2 = df2.drop(dropCols, axis=1)

df = df1.merge(df2, how='left', on=['Player', 'Tm'])
",1.0,2.9132718848303862
41865577.0,I think what you are looking for is going to be more like this...This is assuming df is a list of dictionaries. This will append the country to each dictionary if the number falls into the correct range.,,"for x in df['ip_address']:
    for y in df1:
        if x<=y['upper_bound_ip_address'] and x>=y['lower_bound_ip_address']:
            x['country']=y['country']
",0.95,2.9099149781742275
54591008.0,sql equivalent with where:that would translate to python as:,,"SELECT t1.company,
        t1.resource,
        t2.company,
        t2.resource,
        t1.ClockInDate,
        t2.EffectiveFrom,
        t2.EffectiveTo
FROM table1 t1
LEFT JOIN table2 t2 ON t1.resource = t2.resource
                    AND t1.company = t2.company
WHERE t1.ClockInDate IS NULL --no ClockInDate to check
    OR t2.company IS NULL AND t2.resource IS NULL --not rows in t2 for t1
    OR t1.ClockInDate BETWEEN t2.EffectiveFrom AND t2.EffectiveTo --ClockInDate exists, rows in t2 exist, we can now check ClockInDate to be between t2.EffectiveFrom AND t2.EffectiveTo

df_merge = pd.merge(df1, df2, on=['Company', 'Resource'], how='left')
df_final = df_merge[df_merge.ClockInDate.isnull() | df_merge.ClockInDate.between(df_merge.EffectiveFrom, df_merge.EffectiveTo) | df_merge.EffectiveFrom.isnull()]
",1.0,2.884825687817824
