{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rental-lodge",
   "metadata": {},
   "source": [
    "## Data cleaning and processing\n",
    "<hr>\n",
    "Analysis, cleaning and processing of the original data files is done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metropolitan-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-dispute",
   "metadata": {},
   "source": [
    "## Load data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compound-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>answers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62766758</td>\n",
       "      <td>How to fix Python error \"...failed to map segm...</td>\n",
       "      <td>&lt;p&gt;I've recently started to use Google Cloud P...</td>\n",
       "      <td>python-3.x|pandas|shell|numpy|google-cloud-pla...</td>\n",
       "      <td>&lt;p&gt;Container-Optimized OS (COS) has several li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62766758</td>\n",
       "      <td>How to fix Python error \"...failed to map segm...</td>\n",
       "      <td>&lt;p&gt;I've recently started to use Google Cloud P...</td>\n",
       "      <td>python-3.x|pandas|shell|numpy|google-cloud-pla...</td>\n",
       "      <td>&lt;p&gt;I'm pretty sure that in case of Python libr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62742938</td>\n",
       "      <td>Wrapper for 'python -m' command</td>\n",
       "      <td>&lt;p&gt;I have a package with following structure:&lt;...</td>\n",
       "      <td>python|modulenotfounderror</td>\n",
       "      <td>&lt;p&gt;The standard library has a module &lt;a href=\"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62741826</td>\n",
       "      <td>How can I improve the speed of pandas rows ope...</td>\n",
       "      <td>&lt;p&gt;I have a large .csv file that has 11'000'00...</td>\n",
       "      <td>python|pandas|performance|data-science</td>\n",
       "      <td>&lt;p&gt;Hello and welcome to StackOverflow.&lt;/p&gt;\\n&lt;p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62741826</td>\n",
       "      <td>How can I improve the speed of pandas rows ope...</td>\n",
       "      <td>&lt;p&gt;I have a large .csv file that has 11'000'00...</td>\n",
       "      <td>python|pandas|performance|data-science</td>\n",
       "      <td>&lt;p&gt;I guess you want to &lt;code&gt;groupby&lt;/code&gt; an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  62766758  How to fix Python error \"...failed to map segm...   \n",
       "1  62766758  How to fix Python error \"...failed to map segm...   \n",
       "2  62742938                    Wrapper for 'python -m' command   \n",
       "3  62741826  How can I improve the speed of pandas rows ope...   \n",
       "4  62741826  How can I improve the speed of pandas rows ope...   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>I've recently started to use Google Cloud P...   \n",
       "1  <p>I've recently started to use Google Cloud P...   \n",
       "2  <p>I have a package with following structure:<...   \n",
       "3  <p>I have a large .csv file that has 11'000'00...   \n",
       "4  <p>I have a large .csv file that has 11'000'00...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  python-3.x|pandas|shell|numpy|google-cloud-pla...   \n",
       "1  python-3.x|pandas|shell|numpy|google-cloud-pla...   \n",
       "2                         python|modulenotfounderror   \n",
       "3             python|pandas|performance|data-science   \n",
       "4             python|pandas|performance|data-science   \n",
       "\n",
       "                                             answers  score  \n",
       "0  <p>Container-Optimized OS (COS) has several li...      1  \n",
       "1  <p>I'm pretty sure that in case of Python libr...      0  \n",
       "2  <p>The standard library has a module <a href=\"...      1  \n",
       "3  <p>Hello and welcome to StackOverflow.</p>\\n<p...      1  \n",
       "4  <p>I guess you want to <code>groupby</code> an...      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = spacy.load('en_core_web_sm')\n",
    "\n",
    "df1 = pd.read_csv('data/original_data1.csv')\n",
    "df2 = pd.read_csv('data/original_data2.csv')\n",
    "df3 = pd.read_csv('data/original_data3.csv')\n",
    "df4 = pd.read_csv('data/original_data4.csv')\n",
    "df5 = pd.read_csv('data/original_data5.csv')\n",
    "\n",
    "df = df1.append([df2, df3, df4, df5]).iloc[:, 1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attached-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datebase shape:(100000, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Datebase shape:' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-supplement",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "solid-edmonton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "title      0\n",
       "body       0\n",
       "tags       0\n",
       "answers    0\n",
       "score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-vienna",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "differential-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bhavana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wrapped-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = en.tokenizer(text)\n",
    "    return [token.text.lower() for token in tokens if not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "higher-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'difference', 'between', 'these', 'two', 'dataframes', '?']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(\"What is the difference between these two dataframes?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cooked-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "advisory-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'difference', 'between', 'these', 'two', 'dataframes']\n"
     ]
    }
   ],
   "source": [
    "print(remove_punctuation(tokenize(\"What is the difference between these two dataframes?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "local-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "small-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['difference', 'two', 'dataframes']\n"
     ]
    }
   ],
   "source": [
    "print(remove_stopwords(remove_punctuation(tokenize(\"What is the difference between these two dataframes?\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "southwest-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(words):\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "innocent-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    return ' '.join(normalize(tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "severe-stevens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference two dataframes\n"
     ]
    }
   ],
   "source": [
    "print(process_text(\"What is the difference between these two dataframes?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
