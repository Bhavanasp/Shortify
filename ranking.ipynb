{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/relevant_questions.csv' does not exist: b'data/relevant_questions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0e72f9aea089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrel_que\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/relevant_questions.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/keyword_answer.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/keywords.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/relevant_questions.csv' does not exist: b'data/relevant_questions.csv'"
     ]
    }
   ],
   "source": [
    "#'rel_que' dataframe contains the questions that are relevant to the query which is the output of relevant questions model\n",
    "rel_que = pd.read_csv('data/relevant_questions.csv')\n",
    "#'ans' dataframe contains all the answers with their topics\n",
    "ans = pd.read_csv('data/keyword_answer.csv')\n",
    "#'kdf' dataframe contains the data of keywords for each topic\n",
    "kdf = pd.read_csv('data/keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the length of text\n",
    "def length_text(text):\n",
    "    if(type(text) != type(0.0)):\n",
    "        text = text.split(' ')\n",
    "        return len(text)\n",
    "    else:\n",
    "        return 0\n",
    "ans['ans length'] = ans['answer'].apply(length_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rel_que' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2b4b0b11d348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrel_ans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel_que\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mrel_ans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_ans\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rel_que' is not defined"
     ]
    }
   ],
   "source": [
    "#'rel_ans' dataframe contains the answers corresponding to the relevant questions to the query i.e, questions of 'rel_que' dataset\n",
    "rel_ans = pd.DataFrame()\n",
    "for i in enumerate(rel_que['id']):\n",
    "    rel_ans = pd.concat([ans[ans['id'] == i[1]], rel_ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['Topic 0', 'Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5', 'Topic 6', 'Topic 7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives one-hot encoding of the topics for the answers\n",
    "def get_dataframe(topic_list):\n",
    "    if(type(topic_list) == type(0.0)):\n",
    "        return pd.Series([0,0,0,0,0,0,0,0])\n",
    "    else:\n",
    "        topic_list = topic_list.split(', ')\n",
    "        tl = []\n",
    "        for topic in topics:\n",
    "            if(topic in topic_list):\n",
    "                val = 1\n",
    "            else: \n",
    "                val = 0\n",
    "            tl.append(val)\n",
    "        return pd.Series(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ans[topics] = rel_ans['topic list'].apply(get_dataframe)\n",
    "rel_ans.drop(columns=['topic list'], inplace = True)\n",
    "rel_ans['answer list'] = rel_ans['answer'] + rel_ans['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_text(text):\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     txt = \"\".join([txt.text for txt in soup.find_all(\"p\")])\n",
    "#     return txt\n",
    "\n",
    "# rel_ans['body'] = rel_ans['body'].apply(extract_text)\n",
    "rel_ans['question list'] = rel_que['title'] + rel_ans['body']\n",
    "rel_ans.drop(columns=['title', 'body'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>questions</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48641350</td>\n",
       "      <td>How to merge two lists into a list of multiple...</td>\n",
       "      <td>0.799961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>46362972</td>\n",
       "      <td>Merge list of lists in python 3</td>\n",
       "      <td>0.785947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1158128</td>\n",
       "      <td>Merge sorted lists in python</td>\n",
       "      <td>0.750189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44476206</td>\n",
       "      <td>how to merge two list having dict</td>\n",
       "      <td>0.749920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>58971955</td>\n",
       "      <td>How to merge two dataframe?</td>\n",
       "      <td>0.709934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>14008075</td>\n",
       "      <td>How to merge many to many relations from one d...</td>\n",
       "      <td>0.372127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>55206146</td>\n",
       "      <td>Merge Pandas Dataframe with non-unique index w...</td>\n",
       "      <td>0.366641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>58678560</td>\n",
       "      <td>How to merge similar data into a custom field ...</td>\n",
       "      <td>0.365843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>50727548</td>\n",
       "      <td>How to merge multiple dataframes with the same...</td>\n",
       "      <td>0.354777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>58276538</td>\n",
       "      <td>How to merge/join empty dataframe with another...</td>\n",
       "      <td>0.354546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          questions     score\n",
       "0   48641350  How to merge two lists into a list of multiple...  0.799961\n",
       "1   46362972                    Merge list of lists in python 3  0.785947\n",
       "2    1158128                       Merge sorted lists in python  0.750189\n",
       "3   44476206                  how to merge two list having dict  0.749920\n",
       "4   58971955                        How to merge two dataframe?  0.709934\n",
       "..       ...                                                ...       ...\n",
       "95  14008075  How to merge many to many relations from one d...  0.372127\n",
       "96  55206146  Merge Pandas Dataframe with non-unique index w...  0.366641\n",
       "97  58678560  How to merge similar data into a custom field ...  0.365843\n",
       "98  50727548  How to merge multiple dataframes with the same...  0.354777\n",
       "99  58276538  How to merge/join empty dataframe with another...  0.354546\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>link</th>\n",
       "      <th>code</th>\n",
       "      <th>score</th>\n",
       "      <th>ans length</th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>answer list</th>\n",
       "      <th>question list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4728</td>\n",
       "      <td>58276538.0</td>\n",
       "      <td>You can either use update:output:Or loc:output:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update\\nEmpty_DF.update(ROI_DF)\\r\\n\\n     a   ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You can either use update:output:Or loc:output...</td>\n",
       "      <td>How to merge/join empty dataframe with another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4729</td>\n",
       "      <td>58276538.0</td>\n",
       "      <td>This is perfect case for DataFrame.update, whi...</td>\n",
       "      <td>https://pandas.pydata.org/pandas-docs/stable/r...</td>\n",
       "      <td>DataFrame.update\\nEmpty_DF.update(ROI_DF)\\r\\n\\...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is perfect case for DataFrame.update, whi...</td>\n",
       "      <td>How to merge/join empty dataframe with another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4730</td>\n",
       "      <td>58276538.0</td>\n",
       "      <td>In your case reindex_like</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reindex_like\\nyourdf=ROI_DF.reindex_like(Empty...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In your case reindex_likereindex_like\\nyourdf=...</td>\n",
       "      <td>How to merge/join empty dataframe with another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60589</td>\n",
       "      <td>50727548.0</td>\n",
       "      <td>You can put the different column into index an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pd.concat([plantsFrame.set_index(['plants']), ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You can put the different column into index an...</td>\n",
       "      <td>How to merge multiple dataframes with the same...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27294</td>\n",
       "      <td>58678560.0</td>\n",
       "      <td>Your desired outputs are no longer really mode...</td>\n",
       "      <td>https://stackoverflow.com/a/35019122/12197595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How to merge similar data into a custom field ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39444</td>\n",
       "      <td>46362972.0</td>\n",
       "      <td>Use this code :Ouptut:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>list1= [['user1', 186, 'Feb 2017, Apr 2017', 5...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Use this code :Ouptut:list1= [['user1', 186, '...</td>\n",
       "      <td>Merge list of lists in python 3I have this 2 l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18975</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>This might help</td>\n",
       "      <td>NaN</td>\n",
       "      <td>desiredlist = list(map(lambda y:[lst1,y],lst2)...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This might helpdesiredlist = list(map(lambda y...</td>\n",
       "      <td>How to merge two lists into a list of multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18976</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>You could achieve your desired output with ite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itertools.zip_longest\\nfillvalue\\n&gt;&gt;&gt; from ite...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You could achieve your desired output with ite...</td>\n",
       "      <td>How to merge two lists into a list of multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18977</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>Or you can use use append, but you need to cre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lst3 = []\\r\\nfor elem in lst2:\\r\\n    theNew =...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Or you can use use append, but you need to cre...</td>\n",
       "      <td>How to merge two lists into a list of multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18978</td>\n",
       "      <td>48641350.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from itertools import product\\r\\n\\r\\nlist(prod...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How to merge two lists into a list of multiple...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                             answer  \\\n",
       "4728   58276538.0    You can either use update:output:Or loc:output:   \n",
       "4729   58276538.0  This is perfect case for DataFrame.update, whi...   \n",
       "4730   58276538.0                          In your case reindex_like   \n",
       "60589  50727548.0  You can put the different column into index an...   \n",
       "27294  58678560.0  Your desired outputs are no longer really mode...   \n",
       "...           ...                                                ...   \n",
       "39444  46362972.0                             Use this code :Ouptut:   \n",
       "18975  48641350.0                                    This might help   \n",
       "18976  48641350.0  You could achieve your desired output with ite...   \n",
       "18977  48641350.0  Or you can use use append, but you need to cre...   \n",
       "18978  48641350.0                                                NaN   \n",
       "\n",
       "                                                    link  \\\n",
       "4728                                                 NaN   \n",
       "4729   https://pandas.pydata.org/pandas-docs/stable/r...   \n",
       "4730                                                 NaN   \n",
       "60589                                                NaN   \n",
       "27294      https://stackoverflow.com/a/35019122/12197595   \n",
       "...                                                  ...   \n",
       "39444                                                NaN   \n",
       "18975                                                NaN   \n",
       "18976                                                NaN   \n",
       "18977                                                NaN   \n",
       "18978                                                NaN   \n",
       "\n",
       "                                                    code  score  ans length  \\\n",
       "4728   update\\nEmpty_DF.update(ROI_DF)\\r\\n\\n     a   ...    2.0           6   \n",
       "4729   DataFrame.update\\nEmpty_DF.update(ROI_DF)\\r\\n\\...    3.0          44   \n",
       "4730   reindex_like\\nyourdf=ROI_DF.reindex_like(Empty...    1.0           4   \n",
       "60589  pd.concat([plantsFrame.set_index(['plants']), ...    0.0          12   \n",
       "27294                                                NaN    0.0          46   \n",
       "...                                                  ...    ...         ...   \n",
       "39444  list1= [['user1', 186, 'Feb 2017, Apr 2017', 5...    1.0           4   \n",
       "18975  desiredlist = list(map(lambda y:[lst1,y],lst2)...    0.0           3   \n",
       "18976  itertools.zip_longest\\nfillvalue\\n>>> from ite...    1.0          31   \n",
       "18977  lst3 = []\\r\\nfor elem in lst2:\\r\\n    theNew =...    1.0          16   \n",
       "18978  from itertools import product\\r\\n\\r\\nlist(prod...    1.0           0   \n",
       "\n",
       "       Topic 0  Topic 1  Topic 2  Topic 3  Topic 4  Topic 5  Topic 6  Topic 7  \\\n",
       "4728         0        1        0        0        0        0        0        0   \n",
       "4729         1        1        0        0        1        0        0        0   \n",
       "4730         0        1        0        0        0        0        0        0   \n",
       "60589        0        1        0        0        0        0        0        0   \n",
       "27294        0        1        0        0        0        0        0        1   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "39444        1        0        0        0        0        0        0        1   \n",
       "18975        0        0        0        0        0        0        0        0   \n",
       "18976        0        1        0        0        0        0        0        0   \n",
       "18977        1        1        0        0        0        0        0        0   \n",
       "18978        0        0        0        0        0        0        0        0   \n",
       "\n",
       "                                             answer list  \\\n",
       "4728   You can either use update:output:Or loc:output...   \n",
       "4729   This is perfect case for DataFrame.update, whi...   \n",
       "4730   In your case reindex_likereindex_like\\nyourdf=...   \n",
       "60589  You can put the different column into index an...   \n",
       "27294                                                NaN   \n",
       "...                                                  ...   \n",
       "39444  Use this code :Ouptut:list1= [['user1', 186, '...   \n",
       "18975  This might helpdesiredlist = list(map(lambda y...   \n",
       "18976  You could achieve your desired output with ite...   \n",
       "18977  Or you can use use append, but you need to cre...   \n",
       "18978                                                NaN   \n",
       "\n",
       "                                           question list  \n",
       "4728   How to merge/join empty dataframe with another...  \n",
       "4729   How to merge/join empty dataframe with another...  \n",
       "4730   How to merge/join empty dataframe with another...  \n",
       "60589  How to merge multiple dataframes with the same...  \n",
       "27294  How to merge similar data into a custom field ...  \n",
       "...                                                  ...  \n",
       "39444  Merge list of lists in python 3I have this 2 l...  \n",
       "18975  How to merge two lists into a list of multiple...  \n",
       "18976  How to merge two lists into a list of multiple...  \n",
       "18977  How to merge two lists into a list of multiple...  \n",
       "18978  How to merge two lists into a list of multiple...  \n",
       "\n",
       "[181 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a text processing function which converts text into lowercase, removes any characters like numbers, punctuation, \n",
    "# removes stopwords, stems the words and lemmatises them\n",
    "def text_process(text):\n",
    "    if(type(text) != type(0.0)):\n",
    "        text = text.lower()                              \n",
    "        text = re.sub(\"[^a-z]\", \" \", text)               \n",
    "        text = text.strip()                            \n",
    "        token = word_tokenize(text)\n",
    "        text = [i for i in token if not i in stop_words]\n",
    "        output = []\n",
    "        for word in text:\n",
    "            output.append(stemmer.stem(word))\n",
    "        text = []\n",
    "        for word in output:\n",
    "            text.append(lemmatizer.lemmatize(word))\n",
    "        text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'question list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'question list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8d38c0ccec80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#answers and questions are of 'rel_'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrel_ans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question list'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrel_ans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrel_ans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer list'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrel_ans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bobby\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'question list'"
     ]
    }
   ],
   "source": [
    "#answers and questions are of 'rel_ans' dataframe are preprocessed\n",
    "rel_ans['question list'] = rel_ans['question list'].apply(text_process)\n",
    "rel_ans['answer list'] = rel_ans['answer list'].apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers text scoring and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rel_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function for similarity of the answers with their corresponding questions\n",
    "def cosine_score(question, answer):\n",
    "    if(type(answer) == type(0.0)):\n",
    "        return 0\n",
    "    else:\n",
    "        sentences = [question, answer]\n",
    "        vectorizer = CountVectorizer()\n",
    "        vector = vectorizer.fit_transform(sentences)\n",
    "        text1 = vector.toarray()[0].tolist()\n",
    "        text2 = vector.toarray()[1].tolist()\n",
    "        cosc = 1-distance.cosine(text1, text2)\n",
    "        return cosc\n",
    "\n",
    "#a function that caluclates the sum of tfidf of each word in a text\n",
    "def entropy(text, tfidf_dict):\n",
    "    if(type(text) == type(0.0)):\n",
    "        return 0\n",
    "    else:\n",
    "        token = word_tokenize(text)\n",
    "        entropy = 0.0\n",
    "        for word in token:\n",
    "            try:\n",
    "                entropy = entropy + tfidf_dict[word]\n",
    "            except:\n",
    "                entropy = entropy + 0.0\n",
    "        return entropy\n",
    "\n",
    "#a function that calculates similarity with the query\n",
    "def query_sim_score(query, answer):\n",
    "    score = 0\n",
    "    if(type(answer) == type(0.0)):\n",
    "        return 0\n",
    "    else:\n",
    "        query = query\n",
    "        for q in query:\n",
    "            if(q in answer):\n",
    "                score =  score + 1\n",
    "        score = score/len(query)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text processes the query used in 'relevant questions' model\n",
    "query = 'merge two lists in python'\n",
    "query = text_process(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the frequency of words\n",
    "docs = data['answer list'].dropna().tolist()\n",
    "cv = CountVectorizer(stop_words = stop_words)\n",
    "word_count_vector = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<157x1345 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the tfidf score of each word\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit_transform(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces a dictionary of each word with its tfidf score where the word is the key and tfidf score of the word is the value\n",
    "tfidf_array = tfidf_transformer.idf_\n",
    "words = cv.get_feature_names()\n",
    "tfidf_dict = {}\n",
    "for i in range(0, len(tfidf_transformer.idf_)):\n",
    "    tfidf_dict[words[i]] = tfidf_array[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised_score():\n",
    "    sc = ((score - min_score)/(max_score - min_score))\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnormalises all the scores and returns their weighted sum\n",
    "def score(user_score, cosine_score, entropy_score, sim_score, min_user_score, max_user_score, min_cosine_score, max_cosine_score, min_entropy_score, max_entropy_score):\n",
    "    if(min_user_score == max_user_score):\n",
    "        user_score = user_score - min_user_score\n",
    "    else:\n",
    "        user_score = ((user_score - min_user_score)/(max_user_score - min_user_score))\n",
    "        \n",
    "    if(min_cosine_score == max_cosine_score):\n",
    "        cosine_score = cosine_score - min_cosine_score\n",
    "    else:\n",
    "        cosine_score = ((cosine_score - min_cosine_score)/(max_cosine_score - min_cosine_score))\n",
    "        \n",
    "    if(min_entropy_score == max_entropy_score):\n",
    "        entropy_score = entropy_score - min_entropy_score\n",
    "    else:\n",
    "        entropy_score = ((entropy_score - min_entropy_score)/(max_entropy_score - min_entropy_score))\n",
    "    return (user_score + cosine_score + entropy_score + 2 * sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces a dataframe of the top 15 answers in each topic\n",
    "for topic in topics:\n",
    "    topic_data = data[data[topic]==1][['id', 'answer', 'link', 'code', 'score', 'answer list', 'question list']]\n",
    "    topic_data.dropna()\n",
    "    entropy_score = []\n",
    "    topic_df = pd.DataFrame()\n",
    "    for i in range(0, topic_data.shape[0]):\n",
    "        cosc = cosine_score(topic_data.iloc[i]['question list'], topic_data.iloc[i]['answer list'])\n",
    "        entro = entropy(topic_data.iloc[i]['answer list'], tfidf_dict)\n",
    "        sim_score = query_sim_score(query, topic_data.iloc[i]['answer list'])\n",
    "        topic_df = topic_df.append(pd.Series([topic_data.iloc[i]['id'], topic_data.iloc[i]['answer'], topic_data.iloc[i]['link'], topic_data.iloc[i]['code'], topic_data.iloc[i]['score'], cosc, entro, sim_score]), ignore_index=True)\n",
    "    if topic_df.shape[0]==0:\n",
    "            continue\n",
    "    else:\n",
    "        topic_df.columns = ['id', 'answer', 'link', 'code', 'score', 'cosine score', 'entropy','sim score']\n",
    "        min_user_score = topic_df['score'].min()\n",
    "        max_user_score = topic_df['score'].max()\n",
    "        min_cosine_score = topic_df['cosine score'].min()\n",
    "        max_cosine_score = topic_df['cosine score'].max()\n",
    "        min_entropy_score = topic_df['entropy'].min()\n",
    "        max_entropy_score = topic_df['entropy'].max()\n",
    "        scores = []\n",
    "        for i in range(0, topic_df.shape[0]):\n",
    "            scores.append(score(topic_df.iloc[i]['score'], topic_df.iloc[i]['cosine score'], topic_df.iloc[i]['entropy'], \n",
    "                                topic_df.iloc[i]['sim score'], min_user_score, max_user_score, min_cosine_score, max_cosine_score,\n",
    "                                min_entropy_score, max_entropy_score))\n",
    "        topic_df.drop(columns = ['score', 'cosine score', 'entropy'], inplace=True)\n",
    "        topic_df['sc'] = scores\n",
    "        topic_df.sort_values(by = 'sc', ascending=False, inplace=True, kind='quicksort')\n",
    "        path = 'data/'+ topic +'.csv'\n",
    "        topic_df = topic_df.head(15)\n",
    "        topic_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
